{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import requests\n",
    "import openai\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from IPython.display import Audio\n",
    "from moviepy.editor import AudioFileClip\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Today is:', datetime.datetime.today().strftime ('%d-%b-%Y %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_key = \"OPENAI_API_KEY\"\n",
    "openai.api_base = \"OPENAI_API_BASE\"\n",
    "openai.api_version = \"OPENAI_API_VERSION\"\n",
    "\n",
    "print(\"Open AI version:\", openai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WHISPER_MODEL = \"whisper\"  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_to_text_azureopenai_whisper(sound_file):\n",
    "    \"\"\"\n",
    "    Speech to text with Azure Open AI Whisper\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "\n",
    "    # Prepare the headers\n",
    "    headers = {\n",
    "        \"api-key\": openai.api_key,\n",
    "    }\n",
    "\n",
    "    # Prepare the data for the multipart/form-data request\n",
    "    json = {\n",
    "        \"file\": (sound_file, open(sound_file, \"rb\"), \"audio/mp3\"),\n",
    "        \"locale\": \"en-US\",\n",
    "    }\n",
    "\n",
    "    # Define the API endpoint URL\n",
    "    url = f\"{openai.api_base}/openai/deployments/{WHISPER_MODEL}/audio/transcriptions?api-version=2023-09-01-preview&\"\n",
    "    # Send the POST request\n",
    "    response = requests.post(url, headers=headers, files=json)\n",
    "    # Check the response\n",
    "    if response.status_code == 200:\n",
    "        print(\"Transcription request was successful.\")\n",
    "        transcription_data = response.json()\n",
    "\n",
    "        elapsed = time.time() - start\n",
    "        print(\n",
    "            \"Elapsed time: \"\n",
    "            + time.strftime(\n",
    "                \"%H:%M:%S.{}\".format(str(elapsed % 1)[2:])[:15], time.gmtime(elapsed)\n",
    "            )\n",
    "        )\n",
    "        return transcription_data\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_file = \"rugby.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls $sound_file -lh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_seconds = AudioFileClip(sound_file).duration\n",
    "print(\n",
    "    f\"Audio file duration: {int(duration_seconds // 60)} minutes and {int(duration_seconds % 60)} seconds\"\n",
    ")\n",
    "print(f\"Total number of seconds = {duration_seconds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(sound_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
